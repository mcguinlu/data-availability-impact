### Alfredo

[x] See `report_v2_AST.pdf"

### Julian

I had a few thoughts on reading the paper, as follows:
[x]	Itâ€™s very odd to include table 1 in the background, when it includes results of the current study.
[x]	It looks as if a data availability statement must be mandatory in medRxiv. If so, worth making that point explicitly.
[x]	The description of how the categories in Table 1 were developed is a little vague. I think you should make it clear that (or whether) the categories were developed before you examined the included preprints. Inclusion of quotes from the preprints in Table 1 makes that a little confusing. So does the positioning of the discussion of development of the categories AFTER the section on data extraction. The discussion describes this as "a predefined classification system", so you might as well explain that convincingly.
[x]	You write "When grouped by data-sharing policy, there was a greater change towards open data availability statements in journals requiring/mandating data sharing versus those that encouraged it (Table 2)." Nowhere else (that I can see) is the information that these other journals ENCOURAGED data sharing. Do you have data on that? Or should you describe the comparator simple as not requiring a statement.
[x]	You might consider making Table 3 more informative, since there are only 10 to describe. What was the fate of the 4 that were not "Open" on publication?
[x] Am I right that for code availability you looked only at the preprints and not at subsequent journal publications? You could make that clearer, since "full text manuscripts" could be misinterpreted as the journal paper. (well, I did this until it eventually dawned on me that it meant - I think - the body of the text in the preprints rather than the data availability statement).

### Antica

[x] End of page 3, I think code availablity comes a bit out of the blue. Maybe would be worth to mention it before, and also highlight that this is a computer code (so no like code of conduct)

[x] Table 1, category 8, I would suggest to put something else but GitHub as an example. The github is primary for code, and beacsue this work is more about data maybe better use a more Data-heavy repositiry (e.g. Dryad)

[ ] Just a suggestion: while it is a large sample to check all of the studies, maybe you could have checked a subset of studies claiming they have data, just to see if they really do (My experience is that 1 out of 100 studies providing link to data actually do not have data - e.g. link is broken or data are somethin else then they claim)